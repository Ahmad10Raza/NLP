{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TextBlob : NLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob is a Python library and a simple Natural Language Processing (NLP) tool that is built on top of NLTK (Natural Language Toolkit) and Pattern, another NLP library. TextBlob provides a convenient API for diving into common NLP tasks, such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. It's often used for processing and analyzing textual data in a user-friendly and straightforward manner.\n",
    "\n",
    "Some key features of TextBlob include:\n",
    "\n",
    "1. **Part-of-Speech Tagging:** TextBlob can automatically tag words in a sentence with their corresponding parts of speech, such as nouns, verbs, adjectives, and adverbs.\n",
    "\n",
    "2. **Noun Phrase Extraction:** It can extract noun phrases from text, which can be useful for identifying key concepts in a document.\n",
    "\n",
    "3. **Sentiment Analysis:** TextBlob has built-in sentiment analysis tools that can determine the sentiment polarity (positive, negative, or neutral) of a piece of text.\n",
    "\n",
    "4. **Translation:** It supports translation between different languages using the Google Translate API.\n",
    "\n",
    "5. **Text Classification:** You can use TextBlob to build text classification models, such as spam detection or sentiment classification.\n",
    "\n",
    "6. **Tokenization and Lemmatization:** TextBlob can tokenize text into words and also lemmatize words to their base forms.\n",
    "\n",
    "7. **Spell Checking:** It has basic spell-checking capabilities, which can be helpful for identifying and correcting spelling errors.\n",
    "\n",
    "\n",
    "TextBlob is a user-friendly choice for those who want to perform basic NLP tasks without diving too deep into the complexities of NLP. However, for more advanced or specialized NLP tasks, you might need to use other libraries or frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "wiki=TextBlob(\"Python is a high-level, general-purpose programming language.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech Tagging\n",
    "\n",
    "We can use TextBlob to perform part-of-speech (POS) tagging on a text. Part-of-speech tagging involves identifying the grammatical category or part of speech (e.g., noun, verb, adjective) for each word in a sentence. Here's how you can perform POS tagging using TextBlob:\n",
    "\n",
    "In this example, the `tags` attribute of the TextBlob object contains a list of tuples, where each tuple consists of a word and its associated part of speech tag. The output will look something like:\n",
    "\n",
    "\n",
    "Here are some common part-of-speech tags that you might encounter:\n",
    "\n",
    "- `NN`: Noun\n",
    "- `VBZ`: Verb (3rd person singular present)\n",
    "- `DT`: Determiner\n",
    "- `JJ`: Adjective\n",
    "- `NNP`: Proper noun, singular\n",
    "- `IN`: Preposition or subordinating conjunction\n",
    "- `VBG`: Verb, gerund or present participle\n",
    "- `NNS`: Noun, plural\n",
    "\n",
    "You can use these part-of-speech tags to gain insights into the grammatical structure of the text, which can be useful for various natural language processing tasks, such as information extraction, text summarization, or text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob: NNP\n",
      "is: VBZ\n",
      "a: DT\n",
      "simple: JJ\n",
      "Python: NNP\n",
      "library: NN\n",
      "for: IN\n",
      "processing: VBG\n",
      "textual: JJ\n",
      "data: NNS\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Create a TextBlob object with your text\n",
    "text = \"TextBlob is a simple Python library for processing textual data.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = blob.tags\n",
    "\n",
    "# Print the tagged words and their corresponding parts of speech\n",
    "for word, pos in pos_tags:\n",
    "    print(f\"{word}: {pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('high-level', 'JJ'),\n",
       " ('general-purpose', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textblob\n",
      "python\n",
      "processing textual data\n",
      "noun phrase extraction\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Create a TextBlob object with your text\n",
    "text = \"TextBlob is a simple Python library for processing textual data. It provides tools for part-of-speech tagging, noun phrase extraction, and more.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Extract noun phrases\n",
    "noun_phrases = blob.noun_phrases\n",
    "\n",
    "# Print the extracted noun phrases\n",
    "for np in noun_phrases:\n",
    "    print(np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Sentiment analysis, also known as opinion mining, is a natural language processing (NLP) technique that involves determining the sentiment or emotional tone expressed in a piece of text, such as a sentence, paragraph, or document. Sentiment analysis is often used to classify text as having a positive, negative, or neutral sentiment. TextBlob, a Python library, makes it relatively easy to perform sentiment analysis. Here's how to use TextBlob for sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the text is positive.\n",
      "The sentiment polarity is 0.625.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Create a TextBlob object with your text\n",
    "text = \"I love this product. It's amazing!\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Get sentiment polarity\n",
    "polarity = blob.sentiment.polarity\n",
    "\n",
    "# Determine the sentiment label\n",
    "if polarity > 0:\n",
    "    sentiment = \"positive\"\n",
    "elif polarity < 0:\n",
    "    sentiment = \"negative\"\n",
    "else:\n",
    "    sentiment = \"neutral\"\n",
    "\n",
    "# Print the sentiment and polarity\n",
    "print(f\"The sentiment of the text is {sentiment}.\")\n",
    "print(f\"The sentiment polarity is {polarity}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above:\n",
    "\n",
    "1. We create a TextBlob object from the input text.\n",
    "\n",
    "2. We use the sentiment.polarity attribute to obtain the sentiment polarity. The polarity is a numeric value that indicates how positive or negative the text is. A positive value represents a positive sentiment, a negative value indicates a negative sentiment, and a value close to 0 suggests a neutral sentiment.\n",
    "\n",
    "3. Based on the polarity value, we classify the sentiment as \"positive,\" \"negative,\" or \"neutral.\"\n",
    "\n",
    "4. We print both the sentiment label and the polarity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Tokenization is the process of breaking down a text or a sequence of characters into individual units, typically words or phrases, known as tokens. Tokenization is a fundamental step in natural language processing (NLP) and text analysis, as it allows you to work with and analyze text at a more granular level. In Python, you can use the TextBlob library to tokenize text. Here's how you can tokenize text using TextBlob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization\n",
      "is\n",
      "the\n",
      "process\n",
      "of\n",
      "breaking\n",
      "down\n",
      "text\n",
      "into\n",
      "individual\n",
      "units\n",
      "such\n",
      "as\n",
      "words\n",
      "or\n",
      "phrases\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Create a TextBlob object with your text\n",
    "text = \"Tokenization is the process of breaking down text into individual units, such as words or phrases.\"\n",
    "\n",
    "# Tokenize the text\n",
    "blob = TextBlob(text)\n",
    "tokens = blob.words  # This gives you a list of word tokens\n",
    "\n",
    "# Print the tokens\n",
    "for token in tokens:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Inflection and Lemmatization\n",
    "\n",
    "In natural language processing (NLP), inflection and lemmatization are techniques used to reduce words to their base or root forms. These techniques help in standardizing words so that different inflected forms of the same word can be treated as a single unit, simplifying text analysis. Here's an explanation of both inflection and lemmatization and how to perform them using TextBlob:\n",
    "\n",
    "1. **Inflection:**\n",
    "\n",
    "   Inflection is the process of changing the form of a word to express various grammatical aspects, such as tense, gender, number, and case. For example, in English, the verb \"run\" can have various inflected forms like \"ran,\" \"running,\" or \"runs.\" Inflection can complicate text analysis because different forms of the same word may need to be treated as one.\n",
    "\n",
    "   TextBlob doesn't offer a built-in method for inflection, but you can use its lemmatization capabilities to reduce words to their base forms.\n",
    "\n",
    "2. **Lemmatization:**\n",
    "\n",
    "   Lemmatization is the process of reducing a word to its base or dictionary form, known as the lemma. It involves removing inflections and transformations to get the root word. For example, the lemma of the word \"running\" is \"run,\" and the lemma of \"better\" is \"good.\"\n",
    "\n",
    "   TextBlob provides a lemmatization feature that you can use to find the lemma of a word. Here's how you can perform lemmatization using TextBlob:\n",
    "\n",
    "\n",
    "   In this example, we create a Word object with the word \"running\" and specify that it is a verb (indicated by \"v\"). Then, we use the `.lemmatize()` method to find the lemma of the word. The output will be \"run.\"\n",
    "\n",
    "   Note that you may need to specify the part of speech (POS) of the word you want to lemmatize because some words have different lemmas based on their grammatical role. For example, \"better\" can be an adjective or a verb, and its lemma will be different in each case.\n",
    "\n",
    "Lemmatization is particularly useful when you want to standardize words in your text data for various NLP tasks, such as text classification, information retrieval, or topic modeling. It ensures that words are reduced to their base forms, making it easier to compare and analyze text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "   # Create a Word object\n",
    "word = Word(\"running\")\n",
    "\n",
    "   # Get the lemma of the word\n",
    "lemma = word.lemmatize(\"v\")  # \"v\" indicates that the word is a verb\n",
    "\n",
    "print(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet Integration\n",
    "\n",
    "WordNet is a lexical database for the English language that organizes words into a semantic network, providing information about word meanings, relationships between words, and more. You can integrate WordNet with Python through the NLTK (Natural Language Toolkit) library, which provides access to WordNet's features. Here's how to use WordNet integration with NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms for 'library': library\n",
      "Synonyms for 'library': library\n",
      "Synonyms for 'library': library, depository_library\n",
      "Synonyms for 'library': library, program_library, subroutine_library\n",
      "Synonyms for 'library': library\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Create a TextBlob object\n",
    "text = \"TextBlob is a Python library for NLP.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Find synonyms of a word in the text using WordNet\n",
    "word = \"library\"\n",
    "synsets = wordnet.synsets(word)\n",
    "\n",
    "for synset in synsets:\n",
    "    synonyms = synset.lemma_names()\n",
    "    print(f\"Synonyms for '{word}': {', '.join(synonyms)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cat', 'dog', 'lion', 'tiger'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal=TextBlob(\"cat dog lion tiger\")\n",
    "animal.words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cats', 'dogs', 'lions', 'tigers'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal.words.pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction\n",
    "\n",
    "TextBlob, a Python library, provides basic spelling correction capabilities that can be useful for automatically correcting common spelling errors in text. You can use the .correct() method to correct individual words or phrases within a TextBlob object. Here's how you can perform spelling correction using TextBlob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a house.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Create a TextBlob object with your text\n",
    "text = \"I have a huse.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Correct the spelling within the TextBlob\n",
    "corrected_blob = blob.correct()\n",
    "\n",
    "# Print the corrected text\n",
    "print(corrected_blob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Word and Noun Phrase Frequencies\n",
    "\n",
    "You can use TextBlob to calculate word and noun phrase frequencies in a text. Word frequency analysis involves counting how often each word appears in a text, while noun phrase frequency analysis focuses on counting the occurrences of noun phrases (e.g., multi-word expressions) in the text.\n",
    "\n",
    "Here's how you can calculate word and noun phrase frequencies using TextBlob:\n",
    "\n",
    "```python\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "# Create a TextBlob object with your text\n",
    "text = \"TextBlob is a simple Python library for processing textual data. TextBlob can help with tasks like part-of-speech tagging and sentiment analysis.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Calculate word frequencies\n",
    "word_freq = Counter(blob.words)\n",
    "\n",
    "# Calculate noun phrase frequencies\n",
    "noun_phrase_freq = Counter(blob.noun_phrases)\n",
    "\n",
    "# Print word frequencies\n",
    "print(\"Word Frequencies:\")\n",
    "for word, freq in word_freq.items():\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "# Print noun phrase frequencies\n",
    "print(\"\\nNoun Phrase Frequencies:\")\n",
    "for phrase, freq in noun_phrase_freq.items():\n",
    "    print(f\"{phrase}: {freq}\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "1. We create a TextBlob object from the input text.\n",
    "\n",
    "2. We use the `.words` attribute to tokenize the text into words and calculate word frequencies using the `Counter` class from Python's collections module.\n",
    "\n",
    "3. We use the `.noun_phrases` attribute to extract noun phrases from the text and calculate noun phrase frequencies.\n",
    "\n",
    "4. We print the word and noun phrase frequencies.\n",
    "\n",
    "The output will show the frequencies of words and noun phrases in the text. Note that this example is relatively simple, and in a real-world scenario, you might want to perform additional preprocessing, such as removing stop words or applying lemmatization, for more accurate frequency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequencies:\n",
      "TextBlob: 2\n",
      "is: 1\n",
      "a: 1\n",
      "simple: 1\n",
      "Python: 1\n",
      "library: 1\n",
      "for: 1\n",
      "processing: 1\n",
      "textual: 1\n",
      "data: 1\n",
      "can: 1\n",
      "help: 1\n",
      "with: 1\n",
      "tasks: 1\n",
      "like: 1\n",
      "part-of-speech: 1\n",
      "tagging: 1\n",
      "and: 1\n",
      "sentiment: 1\n",
      "analysis: 1\n",
      "\n",
      "Noun Phrase Frequencies:\n",
      "textblob: 2\n",
      "python: 1\n",
      "processing textual data: 1\n",
      "sentiment analysis: 1\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "# Create a TextBlob object with your text\n",
    "text = \"TextBlob is a simple Python library for processing textual data. TextBlob can help with tasks like part-of-speech tagging and sentiment analysis.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Calculate word frequencies\n",
    "word_freq = Counter(blob.words)\n",
    "\n",
    "# Calculate noun phrase frequencies\n",
    "noun_phrase_freq = Counter(blob.noun_phrases)\n",
    "\n",
    "# Print word frequencies\n",
    "print(\"Word Frequencies:\")\n",
    "for word, freq in word_freq.items():\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "# Print noun phrase frequencies\n",
    "print(\"\\nNoun Phrase Frequencies:\")\n",
    "for phrase, freq in noun_phrase_freq.items():\n",
    "    print(f\"{phrase}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "Parsing is the process of analyzing the grammatical structure of a sentence or text, identifying its constituent parts and their relationships. TextBlob, a Python library, provides some basic parsing capabilities, such as part-of-speech tagging and noun phrase chunking, which can be useful for basic syntactic analysis. Here's how to perform parsing using TextBlob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part-of-Speech Tags:\n",
      "John: NNP\n",
      "and: CC\n",
      "Mary: NNP\n",
      "went: VBD\n",
      "to: TO\n",
      "the: DT\n",
      "park: NN\n",
      "They: PRP\n",
      "had: VBD\n",
      "a: DT\n",
      "picnic: NN\n",
      "\n",
      "Noun Phrases:\n",
      "john\n",
      "mary\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Create a TextBlob object with your text\n",
    "text = \"John and Mary went to the park. They had a picnic.\"\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Part-of-speech tagging\n",
    "pos_tags = blob.tags\n",
    "\n",
    "# Noun phrase chunking\n",
    "noun_phrases = blob.noun_phrases\n",
    "\n",
    "# Print part-of-speech tags\n",
    "print(\"Part-of-Speech Tags:\")\n",
    "for word, pos in pos_tags:\n",
    "    print(f\"{word}: {pos}\")\n",
    "\n",
    "# Print noun phrases\n",
    "print(\"\\nNoun Phrases:\")\n",
    "for np in noun_phrases:\n",
    "    print(np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlobs Are Like Python Strings!\n",
    "\n",
    "TextBlob is designed to make working with textual data in Python more convenient and user-friendly. In some ways, TextBlob can be thought of as an extension of Python strings with additional natural language processing (NLP) functionality. It provides a higher-level API for processing and analyzing text, making it more accessible for those who may not be experts in NLP or linguistics.\n",
    "\n",
    "Here are some ways in which TextBlob is like Python strings:\n",
    "\n",
    "1. **String-Like Operations:** You can perform typical string operations on a TextBlob object, such as indexing, slicing, and concatenation. For example, you can access individual characters or substrings using indexing and slicing as you would with regular strings.\n",
    "\n",
    "2. **Iterability:** TextBlob objects can be iterated over, just like strings, to process text character by character or word by word.\n",
    "\n",
    "3. **String Methods:** Many standard string methods, like `split()`, `strip()`, and `replace()`, can be applied to TextBlob objects for text manipulation.\n",
    "\n",
    "4. **Basic Text Processing:** You can use TextBlob to perform basic text processing tasks, such as lowercasing, uppercasing, and counting the occurrences of specific words or characters.\n",
    "\n",
    "However, TextBlob goes beyond basic string operations by incorporating NLP features like part-of-speech tagging, sentiment analysis, noun phrase extraction, translation, and more. This makes it easier to perform more advanced text analysis tasks without having to implement complex algorithms from scratch or work directly with lower-level NLP libraries.\n",
    "\n",
    "So, while TextBlob retains the characteristics and flexibility of Python strings, it enhances text processing by adding a layer of NLP capabilities, making it a valuable tool for those working with textual data in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams\n",
    "\n",
    "N-grams are contiguous sequences of n items (or words) from a given sample of text or speech. They are widely used in natural language processing (NLP) and computational linguistics for various text analysis tasks, including text generation, language modeling, and feature engineering for machine learning.\n",
    "\n",
    "The \"n\" in \"n-grams\" represents the number of items in the sequence. Here's how n-grams work:\n",
    "\n",
    "1. **Unigrams (1-grams):** These are individual words or characters. For example, in the sentence \"I love pizza,\" the unigrams are \"I,\" \"love,\" and \"pizza.\"\n",
    "\n",
    "2. **Bigrams (2-grams):** These are sequences of two adjacent words or characters. In the same sentence, the bigrams would be \"I love\" and \"love pizza.\"\n",
    "\n",
    "3. **Trigrams (3-grams):** These are sequences of three adjacent words or characters. For the sentence, examples include \"I love pizza.\"\n",
    "\n",
    "4. **N-grams (4-grams, 5-grams, etc.):** These are sequences of n adjacent words or characters, with \"n\" being any positive integer. They can be longer and more informative.\n",
    "\n",
    "N-grams have several applications in NLP:\n",
    "\n",
    "1. **Language Modeling:** N-grams are used to build statistical language models. These models help predict the likelihood of a word or phrase occurring given the preceding n-1 words. They are useful for tasks like text generation, speech recognition, and machine translation.\n",
    "\n",
    "2. **Information Retrieval:** In search engines, n-grams can be used for indexing and searching documents efficiently.\n",
    "\n",
    "3. **Text Classification:** N-grams can be used as features for text classification tasks. By considering sequences of words, they capture more context and can improve classification accuracy.\n",
    "\n",
    "4. **Spell Checking:** N-grams can help identify and correct spelling errors by suggesting corrections based on context.\n",
    "\n",
    "5. **Text Analysis:** N-grams are useful for extracting phrases, collocations, and terminology from text data.\n",
    "\n",
    "However, it's important to note that as \"n\" increases, the number of possible n-grams grows rapidly, and this can lead to issues with data sparsity, especially when dealing with limited training data. N-grams can also miss nuances in language, as they rely on local context and do not capture long-range dependencies.\n",
    "\n",
    "In practice, the choice of n in n-grams depends on the specific NLP task and the characteristics of the text data being analyzed. Researchers and practitioners often experiment with different n-gram sizes to find the most suitable for their applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob is a\n",
      "is a great\n",
      "a great tool\n",
      "great tool for\n",
      "tool for natural\n",
      "for natural language\n",
      "natural language processing\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def generate_ngrams(text, n):\n",
    "    # Create a TextBlob object\n",
    "    blob = TextBlob(text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = blob.words\n",
    "\n",
    "    # Generate n-grams\n",
    "    ngrams = [words[i:i + n] for i in range(len(words) - n + 1)]\n",
    "\n",
    "    return ngrams\n",
    "\n",
    "# Example usage\n",
    "text = \"TextBlob is a great tool for natural language processing.\"\n",
    "n = 3  # 3-grams\n",
    "\n",
    "ngrams = generate_ngrams(text, n)\n",
    "\n",
    "# Print the generated n-grams\n",
    "for ngram in ngrams:\n",
    "    print(\" \".join(ngram))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Thank You!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
