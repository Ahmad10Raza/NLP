{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction To Web Scrapping and Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Web Scrapping?\n",
    "\n",
    "**Web scraping**, also known as web harvesting or web data extraction, is the process of automatically extracting information from websites. It involves using a program or a script to access a website's HTML code, parse the data, and extract specific information from it. This extracted data can then be saved, analyzed, or used for various purposes. Here are some key points to understand about web scraping:\n",
    "\n",
    "**Components of Web Scraping:**\n",
    "\n",
    "1. **HTTP Requests:** Web scraping begins with making HTTP requests to the target website to retrieve its HTML code. This can be done using programming libraries such as Requests in Python.\n",
    "\n",
    "2. **HTML Parsing:** After obtaining the HTML code, web scrapers use HTML parsers (e.g., BeautifulSoup or lxml in Python) to parse the code and extract relevant data.\n",
    "\n",
    "3. **Data Extraction:** Web scrapers identify specific elements on the web page, such as headings, links, tables, or other structured data, and extract the content from those elements. This often involves selecting elements using CSS selectors or XPath expressions.\n",
    "\n",
    "**Use Cases of Web Scraping:**\n",
    "\n",
    "1. **Data Collection:** Web scraping is commonly used to gather data from various websites, including product information from e-commerce sites, real estate listings, news articles, and more.\n",
    "\n",
    "2. **Price Comparison:** Retailers and consumers use web scraping to compare prices of products across different websites and platforms.\n",
    "\n",
    "3. **Market Research:** Companies can scrape data to analyze market trends, monitor competitors, and gather valuable insights.\n",
    "\n",
    "4. **Content Aggregation:** News aggregators and content curation platforms use web scraping to collect news articles and blog posts from various sources.\n",
    "\n",
    "5. **Lead Generation:** Businesses use web scraping to collect contact information (e.g., email addresses) of potential leads for marketing and sales purposes.\n",
    "\n",
    "6. **Research and Analysis:** Researchers and analysts use web scraping to collect data for academic research, sentiment analysis, and more.\n",
    "\n",
    "**Legality and Ethical Considerations:**\n",
    "\n",
    "The legality and ethics of web scraping vary from one website to another and depend on local laws. Some websites may explicitly forbid scraping in their terms of service, while others may allow it to varying degrees. Ethical scraping practices include:\n",
    "\n",
    "- Respecting the website's `robots.txt` file, which specifies which parts of the site can be crawled and scraped.\n",
    "- Avoiding scraping that could overload a website's server and disrupt its operations.\n",
    "- Not collecting and using personal or sensitive data without proper consent or legal basis.\n",
    "\n",
    "It's important to be aware of the legal and ethical considerations when engaging in web scraping and to use this technique responsibly and in compliance with applicable laws and website policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WorkFlow Of Web Scrapping\n",
    "\n",
    "Performing web scraping involves a few key steps and principles:\n",
    "\n",
    "**1. Identify Your Target Website:**\n",
    "   - Choose the website from which you want to scrape data.\n",
    "   - Ensure that you have the legal right to scrape data from this website, and be aware of any terms of service or `robots.txt` file restrictions.\n",
    "\n",
    "**2. Select a Programming Language:**\n",
    "   - You'll need a programming language to write your web scraping code. Python is a popular choice because it has libraries like Requests and BeautifulSoup for web scraping.\n",
    "\n",
    "**3. Set Up Your Development Environment:**\n",
    "   - Install the necessary libraries for your chosen programming language.\n",
    "\n",
    "**4. Send an HTTP Request:**\n",
    "   - Use your programming language to send an HTTP request to the URL of the web page you want to scrape. The response will contain the HTML content of the page.\n",
    "\n",
    "**5. Parse the HTML:**\n",
    "   - Use an HTML parsing library (e.g., BeautifulSoup in Python) to parse the HTML content and create a parse tree. This makes it easier to navigate and extract data from the HTML.\n",
    "\n",
    "**6. Identify the Data to Scrape:**\n",
    "   - Determine which parts of the HTML contain the data you want to scrape. You can often use CSS selectors or XPath expressions to locate specific HTML elements.\n",
    "\n",
    "**7. Extract the Data:**\n",
    "   - Once you've located the relevant HTML elements, extract the data from those elements. For example, you might extract text, links, or images.\n",
    "\n",
    "**8. Store the Data:**\n",
    "   - Store the scraped data in a structured format, such as a CSV file, a database, or a JSON file, depending on your needs.\n",
    "\n",
    "**9. Handle Pagination and Pagination Links:**\n",
    "   - If the data you want is spread across multiple pages, you'll need to implement a method to follow pagination links and scrape data from multiple pages.\n",
    "\n",
    "**10. Handle Dynamic Content (Optional):**\n",
    "   - Some websites load content dynamically using JavaScript. You may need to use a headless browser automation tool like Selenium to interact with the page and scrape dynamic content.\n",
    "\n",
    "**Principles Behind Web Scraping:**\n",
    "\n",
    "1. **Respect the Website's Terms of Service:** Always review the website's terms of service and adhere to their scraping policies. Some websites may explicitly prohibit scraping.\n",
    "\n",
    "2. **Respect `robots.txt`:** Many websites include a `robots.txt` file that specifies which parts of the site can and cannot be scraped. Always respect these guidelines.\n",
    "\n",
    "3. **Avoid Overloading the Server:** Don't send too many requests too quickly, as this can overload the server and disrupt its operations. Use rate limiting and follow best practices for polite web scraping.\n",
    "\n",
    "4. **Use Libraries and Tools:** Make use of existing libraries and tools for web scraping, such as Requests, BeautifulSoup, or Scrapy in Python. These tools simplify the process and handle common tasks.\n",
    "\n",
    "5. **Keep Error Handling in Mind:** When scraping websites, be prepared to handle errors gracefully. Web scraping may encounter issues like HTTP errors, missing data, or changes in website structure.\n",
    "\n",
    "6. **Data Privacy and Legal Compliance:** Be mindful of data privacy and legal compliance, especially when scraping personal or sensitive data.\n",
    "\n",
    "7. **Monitor and Maintain:** Websites can change their structure, so it's important to periodically check and update your scraping code to ensure it remains effective.\n",
    "\n",
    "Web scraping can be a powerful tool for gathering data from the internet, but it should be done responsibly and ethically, with consideration of both legal and ethical principles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools and Libraries Used In Web Scrapping.\n",
    "\n",
    "Web scraping can be made more efficient and convenient by using various tools and libraries. Here are some of the popular tools and libraries used for web scraping:\n",
    "\n",
    "**1. Requests (Library):**\n",
    "   - Language: Python\n",
    "   - Description: Requests is a Python library for making HTTP requests. It's commonly used for fetching the HTML content of web pages, which can then be parsed for data extraction.\n",
    "\n",
    "**2. BeautifulSoup (Library):**\n",
    "   - Language: Python\n",
    "   - Description: BeautifulSoup is a Python library that simplifies the parsing of HTML documents. It makes it easy to navigate and extract data from HTML content.\n",
    "\n",
    "**3. Scrapy (Library):**\n",
    "   - Language: Python\n",
    "   - Description: Scrapy is a powerful web crawling and scraping framework for Python. It provides tools for defining how to follow links and extract data from websites.\n",
    "\n",
    "**4. Selenium (Library/Tool):**\n",
    "   - Language: Multiple (Python, Java, etc.)\n",
    "   - Description: Selenium is a browser automation tool often used for scraping websites with dynamic content. It can simulate user interactions in a web browser to access data that's loaded via JavaScript.\n",
    "\n",
    "**5. Puppeteer (Library/Tool):**\n",
    "   - Language: JavaScript (Node.js)\n",
    "   - Description: Puppeteer is a Node.js library developed by Google for controlling headless Chrome or Chromium browsers. It's commonly used for web scraping and automating browser tasks.\n",
    "\n",
    "**6. Cheerio (Library):**\n",
    "   - Language: JavaScript (Node.js)\n",
    "   - Description: Cheerio is a fast, flexible, and jQuery-like library for parsing and manipulating HTML content on the server-side, making it a useful choice for web scraping in Node.js.\n",
    "\n",
    "**7. lxml (Library):**\n",
    "   - Language: Python\n",
    "   - Description: lxml is a Python library for processing XML and HTML documents. It's known for its speed and efficiency in parsing and extracting data from HTML pages.\n",
    "\n",
    "**8. Nokogiri (Library):**\n",
    "   - Language: Ruby\n",
    "   - Description: Nokogiri is a Ruby library for parsing and searching XML and HTML documents. It is widely used for web scraping in Ruby applications.\n",
    "\n",
    "**9. BeautifulSoup4 (Python Library):**\n",
    "   - Language: Python\n",
    "   - Description: BeautifulSoup4 is an improved version of BeautifulSoup, optimized for Python 3. It provides better support for modern HTML and XML parsing.\n",
    "\n",
    "**10. PyQuery (Python Library):**\n",
    "    - Language: Python\n",
    "    - Description: PyQuery is a Python library that allows you to make jQuery queries on XML documents. It can be a convenient choice for parsing and querying HTML content.\n",
    "\n",
    "**11. Apache Nutch (Tool):**\n",
    "    - Language: Java\n",
    "    - Description: Apache Nutch is an open-source web crawling framework written in Java. It provides a scalable platform for web scraping and indexing web data.\n",
    "\n",
    "**12. Octoparse (Tool):**\n",
    "    - Language: Web-based (No coding required)\n",
    "    - Description: Octoparse is a visual web scraping tool that doesn't require coding. Users can create scraping tasks through a point-and-click interface.\n",
    "\n",
    "**13. Import.io (Tool):**\n",
    "    - Language: Web-based (No coding required)\n",
    "    - Description: Import.io is a cloud-based web scraping tool that allows users to extract data from web pages without writing code.\n",
    "\n",
    "When choosing the right tool or library for web scraping, consider the complexity of the task, the website's structure, and your programming language preferences. Additionally, always ensure that you comply with the website's terms of service and legal regulations when scraping data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what is `nltk` Library ?\n",
    "\n",
    "**NLTK (Natural Language Toolkit)** is a powerful Python library for working with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources, such as WordNet, along with a suite of text processing libraries for tasks like tokenization, stemming, tagging, parsing, and semantic reasoning. NLTK is widely used for natural language processing (NLP) and text analysis tasks. Here are some key features and functionalities of NLTK:\n",
    "\n",
    "**1. Text Processing:** NLTK provides a range of text processing libraries that allow you to work with text data effectively. These include functions for tokenization (splitting text into words or sentences), stemming (reducing words to their root form), and lemmatization (reducing words to their base or dictionary form).\n",
    "\n",
    "**2. Part-of-Speech Tagging:** NLTK includes tools for part-of-speech tagging, which is the process of identifying the grammatical category (e.g., noun, verb, adjective) of each word in a sentence. This is valuable for various NLP tasks.\n",
    "\n",
    "**3. Parsing:** You can use NLTK for parsing sentences and extracting grammatical structures. It includes parsers for context-free grammars and dependency grammars, making it suitable for syntactic and semantic parsing.\n",
    "\n",
    "**4. Named Entity Recognition (NER):** NLTK offers named entity recognition tools that can identify and classify named entities (e.g., names of people, organizations, locations) in text.\n",
    "\n",
    "**5. WordNet Integration:** NLTK integrates with WordNet, a lexical database for English. This allows you to look up word meanings, synonyms, antonyms, and more.\n",
    "\n",
    "**6. Text Corpora:** NLTK provides access to a wide range of text corpora, including large collections of text data for various languages. These corpora are useful for training and testing NLP models.\n",
    "\n",
    "**7. Language Models:** You can build language models, including n-grams and hidden Markov models, for language understanding and generation tasks.\n",
    "\n",
    "**8. Machine Learning Integration:** NLTK can be combined with machine learning libraries like Scikit-learn to create NLP and text classification models.\n",
    "\n",
    "**9. Sentiment Analysis:** NLTK is often used for sentiment analysis, a task that involves determining the emotional tone of a piece of text, such as whether a review is positive or negative.\n",
    "\n",
    "**10. Natural Language Understanding:** NLTK can be employed for a wide range of NLP tasks, from language understanding to text generation, making it a versatile library for working with human language data.\n",
    "\n",
    "NLTK is a valuable resource for both beginners and experts in the field of NLP. It is widely used in research, education, and industry for tasks ranging from basic text processing to more complex language understanding and generation tasks. It provides a foundation for understanding and working with human language data in a computational context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is `re` Library?\n",
    "\n",
    "The `re` library, also known as the \"regular expressions\" or \"regex\" library, is a built-in Python library that provides support for regular expressions. Regular expressions are powerful tools for pattern matching and text manipulation. With the `re` library, you can search for, match, and manipulate strings using complex patterns rather than simple literal text. Here are some key features and use cases of the `re` library:\n",
    "\n",
    "**1. Pattern Matching:** Regular expressions allow you to specify complex patterns to match in text data. These patterns can include a combination of characters, metacharacters, and quantifiers, enabling you to search for specific sequences or structures within strings.\n",
    "\n",
    "**2. Search and Match:** The `re` library provides functions like `search()` and `match()` to find patterns in a string. The `search()` function searches for a pattern anywhere in the input string, while the `match()` function checks if the pattern matches at the beginning of the string.\n",
    "\n",
    "**3. Replacement:** You can use regular expressions to replace matched patterns with other strings. This is particularly useful for data cleaning and manipulation tasks.\n",
    "\n",
    "**4. Splitting:** Regular expressions can be used to split strings into substrings based on a pattern. This is helpful for parsing structured data.\n",
    "\n",
    "**5. Grouping:** You can use parentheses to create groups within a regular expression pattern. This allows you to extract specific parts of a matched string.\n",
    "\n",
    "**6. Quantifiers:** Regular expressions support quantifiers like `*` (zero or more occurrences), `+` (one or more occurrences), `?` (zero or one occurrence), and more, making it possible to describe the repetition of characters or groups.\n",
    "\n",
    "**7. Character Classes:** Character classes like `[a-z]` or `[0-9]` allow you to match specific ranges of characters or digits.\n",
    "\n",
    "**8. Metacharacters:** Metacharacters like `.` (matches any character), `^` (matches the start of a string), and `$` (matches the end of a string) enable you to express more complex matching conditions.\n",
    "\n",
    "**9. Escape Sequences:** You can use escape sequences to match special characters or sequences literally. For example, `\\d` matches a digit, and `\\\\` matches a backslash.\n",
    "\n",
    "**10. Case-Insensitive Matching:** The `re` library provides an option to perform case-insensitive matching by specifying the `re.IGNORECASE` flag.\n",
    "\n",
    "**11. Multiline Matching:** You can match patterns in multi-line text by specifying the `re.MULTILINE` flag.\n",
    "\n",
    "Regular expressions are versatile and can be applied in a wide range of applications, such as data validation, text search and manipulation, data extraction from unstructured text, and more. The `re` library is a fundamental tool for handling textual data in Python and is commonly used in data cleaning, text processing, and text analysis tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrapping Data from `Wikipedia`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # to get the html source code of the page\n",
    "from bs4 import BeautifulSoup # to parse the html source code\n",
    "import re # to use regular expressions\n",
    "from nltk.corpus import stopwords # to remove stopwords\n",
    "from nltk.tokenize import word_tokenize # to tokenize words from sentences\n",
    "from nltk.stem import PorterStemmer # to stem words to their root form (e.g. running -> run)\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download() # download nltk data (stopwords, punkt) if not already downloaded (only need to do this once)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and Parse HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Independence_Day_(India)\"  # Replace with the URL of the webpage you want to scrape\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extracting all paragraphs\n",
    "paragraphs = soup.find_all('p')\n",
    "\n",
    "# Extracting text from each paragraph\n",
    "paragraph_texts = [paragraph.get_text() for paragraph in paragraphs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "lowercase_text = [text.lower() for text in paragraph_texts]\n",
    "\n",
    "# Remove special characters using regex\n",
    "cleaned_text = [re.sub(r'[^a-zA-Z0-9\\s]', '', text) for text in lowercase_text]\n",
    "\n",
    "# Tokenization\n",
    "tokenized_text = [word_tokenize(text) for text in cleaned_text]\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_text = [[word for word in tokens if word not in stop_words] for tokens in tokenized_text]\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_text = [[stemmer.stem(word) for word in tokens] for tokens in filtered_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform additional steps such as removing empty tokens, converting the processed text back to sentences or paragraphs, and so on, based on your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty tokens\n",
    "final_text = [[word for word in tokens if word.strip()] for tokens in stemmed_text]\n",
    "\n",
    "# Convert tokens back to sentences\n",
    "sentences = [' '.join(tokens) for tokens in final_text]\n",
    "\n",
    "# Convert sentences back to paragraphs\n",
    "processed_paragraphs = '\\n\\n'.join(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Propcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "independ day celebr annual 15 august public holiday india commemor nation independ unit kingdom 15 august 1947 day provis indian independ act transfer legisl sovereignti indian constitu assembl came effect india retain king georg vi head state transit republ constitut india came effect 26 januari 1950 celebr indian republ day replac dominion prefix dominion india enact sovereign law constitut india india attain independ follow independ movement note larg nonviol resist civil disobedi led indian nation congress leadership mahatma gandhi\n",
      "\n",
      "independ coincid partit india1 british india divid dominion india pakistan partit accompani violent riot mass casualti displac nearli 15 million peopl due religi violenc 15 august 1947 first prime minist india jawaharl nehru rais indian nation flag lahori gate red fort delhi subsequ independ day incumb prime minist customarili rais flag give address nation2 entir event broadcast doordarshan india nation broadcast usual begin shehnai music ustad bismillah khan independ day observ throughout india flaghoist ceremoni parad cultur event nation holiday345\n",
      "\n",
      "european trader establish outpost indian subcontin late 17th centuri overwhelm militari strength east india compani fought annex local kingdom establish domin forc 18th centuri follow indian rebellion 1857 govern india act 1858 led british crown assum direct control india decad follow civic societi gradual emerg across india notabl indian nation congress parti form 188567 123 period world war mark coloni reform montaguchelmsford reform also wit enact unpopular rowlatt act call selfrul indian activist discont period crystallis nationwid nonviol movement noncooper civil disobedi led mohanda karamchand gandhi7 167\n",
      "\n",
      "1930 reform gradual legisl british congress victori result elections7 195197 next decad beset polit turmoil indian particip world war ii congress final push noncooper upsurg muslim nation led allindia muslim leagu escal polit tension cap independ 1947 jubil temper bloodi partit coloni india india pakistan7 203\n",
      "\n",
      "hasrat mohani first person indian histori demand complet independ azadiekaamil 1929 session indian nation congress purna swaraj declar declar independ india promulgated8 26 januari declar independ day 19308 congress call peopl pledg civil disobedi carri congress instruct issu time time india attain complet independence9 celebr independ day envis stoke nationalist fervour among indian citizen forc british govern consid grant independence10 19 congress observ 26 januari independ day 1930 19461112 celebr mark meet attend took pledg independence10 1920 jawaharl nehru describ autobiographi meet peac solemn without speech exhortation13 gandhi envisag besid meet day would spent construct work whether spin servic untouch reunion hindu mussalman prohibit work even together14 follow actual independ 1947 constitut india came effect 26 januari 1950 sinc 26 januari celebr republ day\n",
      "\n",
      "1946 labour govern britain exchequ exhaust recent conclud world war ii realis neither mandat home intern support reliabl nativ forc continu maintain control increasingli restless india7 203 151617 20 februari 1947 prime minist clement attle announc british govern would grant full selfgovern british india june 1948 latest18\n",
      "\n",
      "new viceroy lord mountbatten advanc date transfer power believ continu content congress muslim leagu might lead collaps interim government19 chose second anniversari japan surrend world war ii 15 august date power transfer19 british govern announc 3 june 1947 accept idea partit british india two states18 successor govern would given dominion statu would implicit right seced british commonwealth indian independ act 1947 10 11 geo 6 c 30 parliament unit kingdom partit british india two new independ dominion india pakistan includ bangladesh effect 15 august 1947 grant complet legisl author upon respect constitu assembl new countries20 act receiv royal assent 18 juli 1947\n",
      "\n",
      "million muslim sikh hindu refuge trek newli drawn border month surround independence21 punjab border divid sikh region halv massiv bloodsh follow bengal bihar mahatma gandhi presenc assuag commun temper violenc mitig 250000 1000000 peopl side new border die violence22 entir nation celebr independ day gandhi stay calcutta attempt stem carnage23 14 august 1947 independ day pakistan new dominion pakistan came muhammad ali jinnah sworn first governor gener karachi\n",
      "\n",
      "constitu assembl india met fifth session 11 pm 14 august constitut hall new delhi24 session chair presid rajendra prasad session jawaharl nehru deliv tryst destini speech proclaim india independ\n",
      "\n",
      "long year ago made tryst destini time come shall redeem pledg wholli full measur substanti stroke midnight hour world sleep india awak life freedom moment come come rare histori step old new age end soul nation long suppress find utter fit solemn moment take pledg dedic servic india peopl still larger caus human\n",
      "\n",
      "member assembl formal took pledg servic countri group women repres women india formal present nation flag assembl\n",
      "\n",
      "dominion india becam independ countri offici ceremoni took place new delhi nehru assum offic first prime minist viceroy lord mountbatten continu first governor general26 6 gandhi name invok crowd celebr occas gandhi howev took part offici event instead mark day 24hour fast spoke crowd calcutta encourag peac hindu muslims26 10\n",
      "\n",
      "0830 swear governor gener minist govern house0940 process minist constitu assembly0950 state drive constitu assembly0955 royal salut governor general1030 hoist nation flag constitu assembly1035 state drive govern house0600 pm flag ceremoni india gate0700 pm illuminations0745 pm firework display0845 pm offici dinner govern house1015 pm recept govern offic\n",
      "\n",
      "day programm 15 august 194726 7\n",
      "\n",
      "independ day one three nation holiday india two republ day 26 januari mahatma gandhi birthday 2 octob observ indian state union territori eve independ day presid india deliv address nation 15 august prime minist hoist indian flag rampart histor site red fort delhi2 speech prime minist highlight past year achiev rais import issu call develop pay tribut leader indian independ movement indian nation anthem jana gana mana sung speech follow march past divis indian arm forc paramilitari forc parad pageant showcas scene independ struggl india divers cultur tradit similar event take place state capit chief minist individu state unfurl nation flag follow parad pageants2728 1973 governor state hoist nation flag state capit februari 1974 chief minist tamil nadu karunanidhi took issu prime minist indira gandhi chief minist like prime minist allow hoist nation flag independ day sinc 1974 chief minist respect state allow hoist nation flag independ day2930\n",
      "\n",
      "flaghoist ceremoni cultur programm take place government nongovernment institut throughout country31 school colleg conduct flag hoist ceremoni variou cultur event government nongovernment institut decor premis paper balloon decor hang freedom fighter portrait wall major govern build often adorn string lights32 delhi citi kite fli add occasion3334 nation flag differ size use abundantli symbolis allegi country35 citizen adorn cloth wristband car household accessori replica tricolour35 period time celebr chang emphasi nation broader celebr thing india3637\n",
      "\n",
      "indian diaspora celebr independ day around world parad pageant particularli region higher concentr indian immigrants38 locat new york us citi 15 august becom india day among diaspora local populac pageant celebr india day either 15 august adjoin weekend day39\n",
      "\n",
      "earli three year independ naga nation council call boycott independ day northeast india40 separatist protest region intensifi 1980 call boycott terrorist attack insurg organis unit liber front assam nation democrat front bodoland mar celebrations41 increas insurg jammu kashmir late 1980s42 separatist protest boycot independ day bandh strike use black flag flag burning434445 terrorist group lashkaretaiba hizbul mujahideen jaishemoham issu threat carri attack around independ day46 boycot celebr also advoc insurg maoist rebel organisations4748\n",
      "\n",
      "anticip terrorist attack particularli milit secur measur intensifi especi major citi delhi mumbai troubl state jammu kashmir4950 airspac around red fort declar nofli zone prevent aerial attacks51 addit polic forc deploy cities52\n",
      "\n",
      "sinc assassin indira gandhi prime minist would give speech behind bulletproof glass panel53 sinc 2014 narendra modi elect prime minist away tradition54 nevertheless addit intens measur taken ensur secur modi55\n",
      "\n",
      "independ day republ day patriot song region languag broadcast televis radio channels56 also play alongsid flaghoist ceremonies56 patriot film broadcast31 decad accord time india number film broadcast decreas channel report audienc oversatur patriot films57 popul belong gener often combin nation popular cultur celebr mixtur exemplifi outfit savouri dy tricolour garment repres india variou cultur traditions3658 shop often offer independ day sale promotions5960 news report decri commercialism596162 indian postal servic publish commemor stamp depict independ movement leader nationalist theme defencerel theme 15 august63\n",
      "\n",
      "independ partit inspir literari artist creations64 creation mostli describ human cost partit limit holiday small part narrative6566 salman rushdi novel midnight children 1980 booker prize booker booker wove narr around children born midnight 1415 august 1947 magic abilities66 freedom midnight 1975 nonfict work larri collin dominiqu lapierr chronicl event surround first independ day celebr 1947 film centr moment independence676869 instead highlight circumst partit aftermath677071 internet googl commemor independ day india sinc 2003 special doodl indian homepage72\n"
     ]
    }
   ],
   "source": [
    "with open('processed_text.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(processed_paragraphs)\n",
    "\n",
    "print(processed_paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank You!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
